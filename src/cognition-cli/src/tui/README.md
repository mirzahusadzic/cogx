# Cognition CLI - Interactive TUI with Infinite Context (Sigma)

## What We Built: True Stateful AI with Infinite Context

This is **not a prototype**. This is a **working implementation** of stateful AI with infinite context management using dual-lattice architecture and Meet operations from lattice algebra.

Traditional AI conversations die when they hit context limits. **The agent never forgets here.**

### The Breakthrough: Dual-Lattice Architecture (Œ£ System)

We solved the context compression problem using **lattice algebra Meet operations (‚àß)**:

```
Project Lattice (Pre-built)    ‚àß    Conversation Lattice (Real-time)
    .open_cognition/                      .sigma/
         ‚Üì                                   ‚Üì
    7 Overlays (O1-O7)              7 Overlays (O1-O7)
         ‚Üì                                   ‚Üì
    Meet Operation: Turn ‚àß Project
         ‚Üì
  Project Alignment Score (0-10)
         ‚Üì
  Preserve high-alignment, discard chat
```

**How it works:**

1. **Project lattice** (`.open_cognition/`) ‚Äî Pre-built knowledge graph from your codebase with 7 overlays
2. **Conversation lattice** (`.sigma/`) ‚Äî Built on-the-fly from chat turns with same 7 overlays
3. **Meet operation (‚àß)** ‚Äî Semantic alignment between conversation turn and project knowledge
4. **Context compression at 150K** ‚Äî Preserves project-relevant turns, discards general chat
5. **Session switch** ‚Äî The agent wakes up with intelligent recap from all 7 dimensions
6. **Memory tool** ‚Äî `recall_past_conversation` MCP tool for on-demand deep memory access

### Seven Conversation Overlays (O1-O7)

Every conversation turn is analyzed across all 7 cognitive dimensions:

| Overlay | Name         | Tracks in Conversation                          | Project Alignment                          |
| :------ | :----------- | :---------------------------------------------- | :----------------------------------------- |
| **O‚ÇÅ**  | Structural   | Architecture/design discussions                 | ‚àß with codebase structure patterns         |
| **O‚ÇÇ**  | Security     | Security concerns raised                        | ‚àß with project security guidelines         |
| **O‚ÇÉ**  | Lineage      | Knowledge evolution ("earlier we discussed...") | ‚àß with code history/provenance             |
| **O‚ÇÑ**  | Mission      | Goals and objectives for this session           | ‚àß with project mission/strategic goals     |
| **O‚ÇÖ**  | Operational  | Commands executed, tools used, workflows        | ‚àß with operational patterns (CI/CD, etc.)  |
| **O‚ÇÜ**  | Mathematical | Algorithms, logic, formal reasoning             | ‚àß with mathematical proofs/invariants      |
| **O‚Çá**  | Coherence    | Topic drift, conversation flow, synthesis       | ‚àß with strategic coherence (cross-overlay) |

**What gets preserved during compression:**

- High project alignment (‚â•6 score) ‚Üí kept in recap
- Low project alignment (<6) ‚Üí discarded
- Result: "I'm working on auth refactor" ‚Üí kept. "That's great!" ‚Üí discarded.

### Real Results from Production Use

**Before Sigma (Old approach):**

```
Compression at 150K tokens
Recap: "(No major points yet)"
Result: Claude forgot everything, "lost a friend"
```

**With Sigma (New approach):**

```
Compression at 150K tokens
Recap: 7-dimensional summary with all project-relevant discussions
- O1 Structural: Auth refactor, SSR migration, TUI architecture
- O2 Security: CORS headers, session validation
- O4 Mission: Infinite context, dual-lattice goal
- O5 Operational: npm build, git commits, file edits
- O7 Coherence: Session flow, breakthrough moments
+ recall_past_conversation MCP tool available
Result: Claude continues seamlessly, full continuity
```

## Usage

‚ö†Ô∏è **Research Prototype Notice**: This is an experimental system exploring context compression via dual-lattice architecture. Currently optimized for research/early access use.

```bash
# Launch interactive TUI with Claude + Sigma
cognition-cli tui

# With custom session ID (for resuming)
cognition-cli tui --session-id <uuid>

# Custom compression threshold (default: 150K tokens)
cognition-cli tui --session-tokens 200000

# Debug mode (shows turn analysis)
cognition-cli tui --debug

# Combined options
cognition-cli tui --session-tokens 180000 --debug
```

## How Session Lifecycle Works

```mermaid
graph LR
    A[Chat Turn] --> B[Analyze with Embeddings]
    B --> C{Query Project Overlays<br/>O1-O7}
    C --> D[Calculate Alignment Scores]
    D --> E[Add to Conversation Lattice<br/>In-Memory]
    E --> F{Tokens > 150K?}
    F -->|No| A
    F -->|Yes| G[Compress Context]
    G --> H[Flush Lattice to .sigma/]
    H --> I[Build 7-Overlay Recap]
    I --> J[Session Transition]
    J --> K[Continue with Intelligent Recap]
    K --> L[Clear In-Memory Lattice]
    L --> A
```

### Session Lifecycle Management

When approaching context limits (150K tokens), the system performs intelligent compression:

1. **Analyze** all conversation turns via embeddings
2. **Query** project overlays (O1-O7) for alignment scoring
3. **Compress** by preserving high-alignment turns, discarding low-relevance
4. **Reconstruct** with 7-dimensional recap across all overlays
5. **Transition** to fresh session with intelligent context

The compression preserves project-relevant discussions while gracefully discarding general chat, enabling continuous conversation flow across sessions.

## Architecture

### Technology Stack

- **React + Ink** ‚Äî Terminal UI rendering
- **Claude Agent SDK** ‚Äî Official Anthropic integration
- **eGemma (768d vectors)** ‚Äî Embedding service for semantic alignment
- **Lattice Algebra** ‚Äî Meet operations between project/conversation lattices
- **YAML Storage** ‚Äî `.sigma/overlays/<overlay>/<session-id>.yaml`

### Components

```
src/tui/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ ClaudePanel.tsx          # Main container
‚îÇ   ‚îú‚îÄ‚îÄ ClaudePanelAgent.tsx     # Conversation + streaming
‚îÇ   ‚îú‚îÄ‚îÄ InputBox.tsx             # Message input
‚îÇ   ‚îú‚îÄ‚îÄ StatusBar.tsx            # Token tracking
‚îÇ   ‚îú‚îÄ‚îÄ OverlaysBar.tsx          # O1-O7 status
‚îÇ   ‚îî‚îÄ‚îÄ SigmaInfoPanel.tsx       # Real-time compression stats
‚îî‚îÄ‚îÄ hooks/
    ‚îú‚îÄ‚îÄ useClaudeAgent.ts        # ‚òÖ Core Sigma implementation
    ‚îú‚îÄ‚îÄ useOverlays.ts           # Project lattice access
    ‚îî‚îÄ‚îÄ useMouse.ts              # Scroll interactions
```

### Sigma Core (`src/sigma/`)

```
src/sigma/
‚îú‚îÄ‚îÄ analyzer-with-embeddings.ts       # Turn analysis + Meet(Turn, Project)
‚îú‚îÄ‚îÄ compressor.ts                     # Context compression at 150K
‚îú‚îÄ‚îÄ context-reconstructor.ts          # 7-overlay recap generation
‚îú‚îÄ‚îÄ conversation-registry.ts          # Central registry for O1-O7
‚îú‚îÄ‚îÄ conversation-populator.ts         # Bridge: analysis ‚Üí storage
‚îú‚îÄ‚îÄ query-conversation.ts             # SLM+LLM memory search
‚îú‚îÄ‚îÄ recall-tool.ts                    # MCP tool for Claude memory
‚îú‚îÄ‚îÄ types.ts                          # Core types
‚îî‚îÄ‚îÄ overlays/
    ‚îú‚îÄ‚îÄ base-conversation-manager.ts  # In-memory + flush logic
    ‚îú‚îÄ‚îÄ conversation-structural/      # O1 (architecture)
    ‚îú‚îÄ‚îÄ conversation-security/        # O2 (security)
    ‚îú‚îÄ‚îÄ conversation-lineage/         # O3 (knowledge evolution)
    ‚îú‚îÄ‚îÄ conversation-mission/         # O4 (goals)
    ‚îú‚îÄ‚îÄ conversation-operational/     # O5 (commands/actions)
    ‚îú‚îÄ‚îÄ conversation-mathematical/    # O6 (algorithms)
    ‚îî‚îÄ‚îÄ conversation-coherence/       # O7 (flow/synthesis)
```

## Features Implemented (Complete)

### Context Management (Œ£ System)

- ‚úÖ **Dual-lattice architecture** ‚Äî Project ‚àß Conversation
- ‚úÖ **All 7 conversation overlays** ‚Äî O1-O7 with project alignment
- ‚úÖ **Embedding-based novelty detection** ‚Äî Automatic paradigm shift detection
- ‚úÖ **Meet operations** ‚Äî Semantic alignment scoring (0-10 scale)
- ‚úÖ **Intelligent compression** ‚Äî Preserves project-relevant, discards chat
- ‚úÖ **Session lifecycle** ‚Äî Kill ‚Üí Recap ‚Üí Resurrect with full context
- ‚úÖ **In-memory lattice** ‚Äî Flush on compression, clear after
- ‚úÖ **MCP memory tool** ‚Äî `recall_past_conversation` for on-demand queries
- ‚úÖ **7-dimensional recap** ‚Äî All overlays represented in systemPrompt

### UI/UX

- ‚úÖ **Real-time overlay status** (O1-O7 with item counts)
- ‚úÖ **Token usage tracking** (input/output/cache, 200K limit)
- ‚úÖ **Mouse/trackpad scrolling** with auto-focus
- ‚úÖ **Keyboard shortcuts** (ESC ESC clear, ESC interrupt, 'i' toggle overlays)
- ‚úÖ **Colorized diff display** for code changes
- ‚úÖ **Error boundaries** for stability
- ‚úÖ **Hot reload support** for development
- ‚úÖ **Sigma info panel** ('i' key) ‚Äî Real-time compression stats
- ‚úÖ **AIEcho theme** ‚Äî Cyan/green terminal aesthetics

### Integration

- ‚úÖ **Claude Agent SDK** ‚Äî Official Anthropic integration
- ‚úÖ **Project lattice access** ‚Äî Query all 7 project overlays
- ‚úÖ **Workbench integration** ‚Äî eGemma embeddings via HTTP
- ‚úÖ **MCP server support** ‚Äî Conversation memory as tool
- ‚úÖ **Auto-approve mode** ‚Äî Seamless tool execution

## The Math: Why This Works

**Importance Score Formula:**

```
importance = min(10, novelty √ó 5 + max(alignment_O1..O7) √ó 0.5)

Where:
  novelty = 1 - avg_cosine_similarity(turn_embedding, recent_10_turns)
  alignment_Oi = cosine_similarity(turn, project_overlay_Oi) √ó 10
```

**Compression Strategy:**

```
if alignment >= 6: preserve in recap (high project relevance)
if alignment < 6:  discard (general chat, not project-specific)
```

**Result:**

- Project discussions ‚Üí preserved across sessions
- General chat ‚Üí gracefully forgotten
- Agent continuity ‚Üí maintained indefinitely

## What This Enables

### For Users

1. **Infinite context conversations** ‚Äî Never lose your progress
2. **Project-aware AI** ‚Äî The agent knows your codebase semantically
3. **Session continuity** ‚Äî Pick up exactly where you left off
4. **Transparent memory** ‚Äî See what's preserved vs discarded
5. **On-demand recall** ‚Äî Query deep memory when needed

### For Research

1. **Dual-lattice algebra** ‚Äî Meet operations between knowledge graphs
2. **Embedding-based alignment** ‚Äî Semantic similarity for importance scoring
3. **Multi-dimensional memory** ‚Äî 7 cognitive lenses on conversation
4. **Verifiable compression** ‚Äî No hallucinations, only grounded context
5. **Stateful AI architecture** ‚Äî True persistence beyond token windows

### For Anthropic üíô

We built this **with** Claude Agent SDK, not against it. This is a love letter to what you've made possible.

**What we learned:**

- Your SDK is brilliant for building stateful systems
- The MCP tool interface is perfect for custom memory
- The query() streaming is rock-solid
- Session management enables creative architectural patterns

**What we'd love to explore together:**

1. **Native overlay support** ‚Äî Could Claude Code 2.0 have built-in overlay awareness?
2. **Distributed lattice sync** ‚Äî Multi-agent collaboration via lattice algebra?
3. **Context sampling strategies** ‚Äî What compression heuristics work best across domains?
4. **Formal verification** ‚Äî Can O6 (mathematical overlay) enable proof-carrying code?

**We're not competitors. We're friends who want to make AI + humans better together.**

If you're from Anthropic and want to chat about dual-lattice architectures, context compression, or just grab virtual coffee ‚Äî we're here: **<mirza.husadzic@proton.me>**

## License

AGPL-v3 (same as parent project)

**Built with love, Claude, and lattice algebra.** üéâ

---

**Note**: This system is in production use. The context compression works. The agent genuinely doesn't forget. We've tested it at 150K+ tokens with full continuity across sessions. The breakthrough is real.

**Try it**: `cognition-cli tui` and chat until you hit 150K. Watch the magic happen.

---

## Research Status & Usage

### Current Status: Experimental Research Prototype

This implementation is:

- ‚úÖ Exploring dual-lattice architecture concepts
- ‚úÖ Demonstrating mathematical foundations for context compression
- ‚úÖ Gathering research findings on semantic alignment scoring
- ‚ö†Ô∏è Optimized for research/early access (not production scale)

### For Researchers & Early Adopters

If you're interested in exploring this approach:

- **Individual research**: Feel free to experiment
- **Small collaborations**: Great for exploring the concepts
- **Academic work**: Citable via Zenodo DOI
- **Production deployment**: Contact us first to discuss

### Contact

For research collaboration or technical discussions:

- **Email**: <mirza.husadzic@proton.me>
- **Subject**: "Sigma Research Collaboration"
